#!/bin/bash
export SITE_NAME=`uname -n`
export PYSPARK_DRIVER_PYTHON=/usr/bin/ipython
export LD_PRELOAD=/opt/intel/composerxe/compiler/lib/intel64/libiomp5.so:/opt/intel/composerxe/mkl/lib/intel64/libmkl_rt.so
export SPARK_PARAMETERS="--packages com.databricks:spark-csv_2.11:1.2.0 --driver-memory 8G --executor-memory 4G --driver-cores 8 --total-executor-cores 64 --executor-cores 8 --driver-class-path /etc/hadoop/hdfs-site.xml:/etc/hadoop/core-site.xml:/etc/hadoop --master mesos://zk://10.0.12.58:2181,10.0.12.59:2181,10.0.12.51:2181,10.0.12.52:2181,10.0.12.60:2181,10.0.12.61:2181,10.0.12.18:2181/mesos"
export PYSPARK_DRIVER_PYTHON_OPTS="notebook --ip='*'"
export SPARKR_SUBMIT_ARGS="${SPARK_PARAMETERS} sparkr-shell " 
# export JAVACMD="/opt/spark/bin/spark-shell"
/opt/spark/bin/pyspark --name "PySpark Notebook " ${SPARK_PARAMETERS}
