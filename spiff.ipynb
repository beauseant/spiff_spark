{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import timeit\n",
    "import re\n",
    "from operator import add\n",
    "\n",
    "startt = timeit.default_timer()\n",
    "\n",
    "path = '/export/usuarios01/sblanco/Datos/repogit/spiff_spark/'\n",
    "path_out = '/export/usuarios01/sblanco/Datos/repogit/spiff_spark/Output/salida.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def countWords ( cad ):\n",
    "    return ( [word for word in re.findall(r'\\b[^\\W\\d_]+\\b',cad)])\n",
    "\n",
    "\n",
    "def getData ( cad ):\n",
    "    \n",
    "        autor = '-1'\n",
    "        match_menciones = []\n",
    "        match_etiquetas = []\n",
    "        match_urls = []\n",
    "        \n",
    "        salida = []\n",
    "        try:\n",
    "            cad = cad.strip ()\n",
    "            \n",
    "            #El autor es la primera arroba:    \n",
    "            match = re.search (r'@[\\w\\.-]+', cad) \n",
    "            autor =  match.group(0)\n",
    "            \n",
    "            \n",
    "            #Dejamos la cadena sin el autor para seguir buscando en ella:\n",
    "            inicio_autor = cad.find('@') + 1\n",
    "            fin_autor = cad.find(' ',inicio_autor)\n",
    "            cad = cad[fin_autor+1:]\n",
    "\n",
    "            #Buscamos todas las menciones que aparezcan:\n",
    "            match_menciones = re.findall(r'@[\\w\\.-]+', cad)\n",
    "            \n",
    "            #y las etiquetas:\n",
    "            match_etiquetas = re.findall(r'#[\\w\\.-]+', cad)\n",
    "\n",
    "            #y las urls:\n",
    "            match_urls = re.findall(r'(https?://[^\\s]+)',cad)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        except Exception as e:\n",
    "                match_menciones = [str(e)]\n",
    "                match_urls = [cad]\n",
    "        \n",
    "        \n",
    "        salida = [ match_menciones, match_etiquetas, match_urls ]\n",
    "            \n",
    "    \n",
    "        #salida[0]: autor\n",
    "        #salida[1][0]: lista de menciones, salida[1][0][0] primera mencion\n",
    "        #salida[1][1]: etiquetas\n",
    "        return autor, salida\n",
    "    \n",
    "def toCSV (rd_tweets, f):\n",
    "    \n",
    "    datasep = ';'\n",
    "    listsep = ','\n",
    "    \n",
    "    myF = open (f, 'w')\n",
    "    \n",
    "    for tw in rd_tweets.collect():\n",
    "        line = tw[0] + datasep\n",
    "        \n",
    "        for menc in tw[1][0]:\n",
    "            line = line + menc + listsep\n",
    "            \n",
    "        line = line + datasep\n",
    "        \n",
    "        for etiqu in tw[1][1]:\n",
    "            line = line + etiqu + listsep\n",
    "        \n",
    "        myF.write (line + '\\n')\n",
    "        \n",
    "    myF.close()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tweets fallidos: 7879\n",
      "Los 10 autores con mas entradas son:[('-1', 7879), (u'@TunisiaTrends', 1815), (u'@SBZ_news', 1638), (u'@nawaat', 1524), (u'@Dima_Khatib', 1482), (u'@weddady', 1466), (u'@LiveWordCanada', 1234), (u'@halmustafa', 1149), (u'@TunObs', 1114), (u'@WikiActions', 958)]\n"
     ]
    }
   ],
   "source": [
    "#tweets = sc.textFile('file:///export/usuarios01/sblanco/Datos/repogit/spiff_spark/Data/03_10_2016/red.txt')\n",
    "file_path = 'file://'+ path + '/Data/03_10_2016/todo.txt'\n",
    "tweets = sc.textFile(file_path)\n",
    "\n",
    "alldata = tweets.map ( getData )\n",
    "\n",
    "#Errores procesados, o buscar un autor concreto:\n",
    "author = '-1'\n",
    "print 'tweets fallidos: %s' % (alldata.filter (lambda x : x[0]==author).count())\n",
    "\n",
    "\n",
    "#Autor con mas entradas:\n",
    "count = 10\n",
    "moreentr = alldata.map ( lambda x: [x[0],1]).reduceByKey ( add ).takeOrdered( count ,key=lambda x: -x[1])\n",
    "print 'Los %s autores con mas entradas son:%s' % (str(count), str(moreentr))\n",
    "\n",
    "toCSV ( alldata, path_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total time:4.75341296196\n"
     ]
    }
   ],
   "source": [
    "print 'Total time:%s' % (timeit.default_timer() - startt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
